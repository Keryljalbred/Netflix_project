{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9afc4d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h1> Exercice </h1>\n",
    "\n",
    "Le dataset \"Titres Netflix\" est une compilation exhaustive de films et de séries télévisées disponibles sur Netflix, couvrant divers aspects tels que le type de titre, le réalisateur, les acteurs, le pays de production, l'année de sortie, la classification, la durée, les genres (répertoriés dans) et une brève description. Ce dataset est essentiel pour analyser les tendances du contenu Netflix, comprendre la popularité des genres et examiner la distribution du contenu à travers différentes régions et périodes.\n",
    "\n",
    "Les colonnes : \n",
    "- show_id : Un identifiant unique pour chaque titre.\n",
    "- type : La catégorie du titre, qui peut être 'Film' ou 'Série télévisée'.\n",
    "- title : Le nom du film ou de la série télévisée.\n",
    "- director : Le(s) réalisateur(s) du film ou de la série télévisée. (Contient des valeurs nulles pour certaines entrées, en particulier les séries télévisées où cette information peut ne pas être applicable.)\n",
    "- cast : La liste des acteurs principaux du titre. (Certaines entrées peuvent ne pas avoir cette information.)\n",
    "- country : Le pays ou les pays où le film ou la série télévisée a été produit.\n",
    "- date_added : La date à laquelle le titre a été ajouté à Netflix.\n",
    "- release_year : L'année de sortie originale du film ou de la série télévisée.\n",
    "- rating : La classification par âge du titre.\n",
    "- duration : La durée du titre, en minutes pour les films et en saisons pour les séries télévisées.\n",
    "- listed_in : Les genres auxquels appartient le titre.\n",
    "- description : Un bref résumé du titre.\n",
    "\n",
    "<h1> Enoncé </h1>\n",
    "\n",
    "<h2> data cleaning & data modeling </h2>\n",
    "\n",
    "<b> 1) Importation du fichier </b>\n",
    "\n",
    "Tentez d'importer le fichier netflix_titles.csv. Si vous rencontrez une erreur, celle-ci est probablement liée à un problème d'encodage. Trouvez l'encodage adéquat pour lire le fichier correctement.\n",
    "\n",
    "<b> 2) Création d'une copie du DataFrame </b>\n",
    "\n",
    "Créez une copie de votre DataFrame dans une nouvelle variable afin de conserver les données originales accessibles.\n",
    "\n",
    "<b> 3) Suppression des colonnes inutiles </b>\n",
    "\n",
    "Vérifiez que les colonnes nommées \"Unnamed:...\" en fin de DataFrame ne contiennent aucune donnée, puis supprimez-les.\n",
    "\n",
    "<b> 4) Définition d'un nouvel index </b>\n",
    "\n",
    "Assurez-vous que la colonne \"Show_id\" ne possède ni valeur nulle ni doublon. Si c'est le cas, définissez show_id comme index du DataFrame.\n",
    "\n",
    "<b> 5) Correction du type de colonne </b>\n",
    "Vérifiez le type de la colonne \"Date_added\" et corrigez-le avec le type adéquat si nécessaire.\n",
    "\n",
    "<b> 6) Gestion de la colonne \"Duration\" </b>\n",
    "\n",
    "- Confirmez que la colonne \"Type\" contient uniquement les valeurs 'Movie' et 'TV Show'.\n",
    "- Examinez la nomenclature des valeurs de la colonne \"Duration\".\n",
    "- Via un groupby, vérifiez que les durées sont bien associées à une durée en minutes pour les films et à un nombre de saisons pour les séries.\n",
    "- Créez une nouvelle colonne 'duration (movies)' pour isoler le nombre de minutes pour les films. Assurez-vous que cette  colonne soit de type \"float\".\n",
    "- Créez une colonne 'seasons (TV Show)' pour isoler le nombre de saisons pour les séries. Assurez-vous que cette colonne soit de type \"float\".\n",
    "- Supprimez finalement la colonne 'Duration' du dataset.\n",
    "\n",
    "<b> 7) Création de DataFrames annexes pour les valeurs séparées par des virgules </b>\n",
    "\n",
    "Certaines colonnes comme country, cast et listed_in contiennent pour certains titres des séries de valeurs, sépérées par des virgules. Nous souhaitons créer des tableaux annexes permettant d'avoir chaque valeur de manière distincte.\n",
    "\n",
    "Pour la colonne \"Country\" :\n",
    "- Créez une colonne 'countries' en transformant les valeurs de la colonne 'country' en listes (via str.split).\n",
    "- Créez un DataFrame 'countries_exploded' qui génère une ligne pour chaque pays via la méthode .explode().\n",
    "- Isolez uniquement la colonne 'countries' dans le DataFrame 'countries_exploded' (non vue en cours, à vous de comprendre son fonctionnement : https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html)\n",
    "- Répétez ce processus pour les colonnes 'categories' (basée sur 'listed_in') et 'cast', créant respectivement les - DataFrames 'categories_exploded' et 'cast_list'.\n",
    "\n",
    "<b> 8) Suppression des colonnes transformées </b>\n",
    "\n",
    "Supprimez les trois colonnes transformées du DataFrame original.\n",
    "\n",
    "<b> 9) Création de colonnes temporelles </b>\n",
    "\n",
    "À partir de 'Date Added', créez des colonnes pour l'année d'ajout, le mois d'ajout et le jour de la semaine d'ajout.\n",
    "Analyse des Données\n",
    "\n",
    "<h2> Analyse des données </h2>\n",
    "\n",
    "Tentez maintenant de répondre aux questions suivantes : \n",
    "\n",
    "1) Combien de \"shows\" sont présents dans ce dataset ?\n",
    "2) Quelle est la répartition entre les types 'Movie' et 'TV Show' ?\n",
    "3) Quelle est la répartition des ajouts en fonction de l'année ?\n",
    "4) Quel est le top 5 des catégories de shows les plus ajoutées ?\n",
    "5) Quel est le top 5 des comédiens les plus plébiscités aux États-Unis ?\n",
    "6) Quelle est la répartition des ajouts en fonction du jour de la semaine ?\n",
    "7) Dans quel pays sont produits le plus de documentaires ?\n",
    "8) En moyenne, combien de saisons ont les séries ?\n",
    "9) Quelle est la distribution des films en fonction de leur durée (quartiles) ?\n",
    "10) Combien de shows ont pour thématique la drogue (présence du mot \"drug\" dans la description) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee6df90",
   "metadata": {},
   "source": [
    "<h1> Data Cleaning et data modeling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac0206-8cdc-4c0a-a833-b9eb2c90a7d2",
   "metadata": {},
   "source": [
    "<h4>Importation des fichiers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "598d0876-38aa-4849-9c88-694554a35a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "# Lire le fichier en mode binaire\n",
    "with open('netflix_titles.csv', 'rb') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Décoder le contenu avec l'encodage approprié\n",
    "content_str = content.decode('ISO-8859-1')\n",
    "\n",
    "# Diviser le contenu en lignes\n",
    "lines = content_str.splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7e252-1deb-4755-bb80-e65bb6ffe3d2",
   "metadata": {},
   "source": [
    "<h4>Création d'une copie du DataFrame</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "36ce6c08-7b3e-46a3-b869-95490f6edc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier le nombre de colonnes\n",
    "num_columns = len(lines[0].split(','))  # Nombre de colonnes de l'en-tête\n",
    "cleaned_lines = []\n",
    "# Vérifier le nombre de colonnes\n",
    "num_columns = len(lines[0].split(','))  # Nombre de colonnes de l'en-tête\n",
    "cleaned_lines = []\n",
    "\n",
    "for line in lines:\n",
    "    if len(line.split(',')) == num_columns:  # Vérifier si le nombre de colonnes correspond\n",
    "        cleaned_lines.append(line)\n",
    "\n",
    "# Créer une copie de la DataFrame nettoyée\n",
    "data_copy = np.array(cleaned_lines)\n",
    "for line in lines:\n",
    "    if len(line.split(',')) == num_columns:  # Vérifier si le nombre de colonnes correspond\n",
    "        cleaned_lines.append(line)\n",
    "\n",
    "# Créer une copie de la DataFrame nettoyée\n",
    "data_copy = np.array(cleaned_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cabe4f-7d50-46fd-9c74-b51398e5ee02",
   "metadata": {},
   "source": [
    "<h4> Suppression des colonnes inutiles</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "7b1a3ed9-def4-41df-9f45-e64aeadcfee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir en tableau structuré NumPy\n",
    "data = np.genfromtxt(data_copy, delimiter=',', dtype=None, encoding='utf-8', names=True)\n",
    "\n",
    "# Vérifier et supprimer les colonnes \"Unnamed\"\n",
    "columns_to_keep = [col for col in data.dtype.names if 'Unnamed' not in col]\n",
    "data_cleaned = np.zeros(data.shape[0], dtype=[(name, data.dtype[name]) for name in columns_to_keep])\n",
    "\n",
    "for name in columns_to_keep:\n",
    "    data_cleaned[name] = data[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1211a6-1c0d-424d-9977-2e5696bbd6fe",
   "metadata": {},
   "source": [
    "<h4> Définition d'un nouvel index</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "8234d836-f8cc-4734-ab37-2542682991c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les doublons et les valeurs nulles dans \"show_id\"\n",
    "show_id_index = np.where(data_cleaned['show_id'] == '')[0]\n",
    "if show_id_index.size == 0:\n",
    "    # Ne rien faire, car il n'y a pas de doublons ou de valeurs nulles\n",
    "    pass\n",
    "else:\n",
    "    print(\"Erreur : 'show_id' contient des valeurs nulles ou des doublons.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0f47d4-67c1-4392-aa48-d88799b12c45",
   "metadata": {},
   "source": [
    "<h4> Correction du type de colonne</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "a7b9dcbf-2bec-4aad-a319-c79b456fdf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier et convertir \"date_added\" en datetime\n",
    "date_added_as_datetime = []\n",
    "\n",
    "for date in data_cleaned['date_added']:\n",
    "    if isinstance(date, str) and date.strip():  \n",
    "        try:\n",
    "            date_added_as_datetime.append(datetime.strptime(date, '%B %d, %Y'))\n",
    "        except ValueError:\n",
    "            date_added_as_datetime.append(np.nan)  \n",
    "    else:\n",
    "        date_added_as_datetime.append(np.nan)  \n",
    "\n",
    "# Convertir en tableau NumPy\n",
    "date_added_as_datetime = np.array(date_added_as_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef08bfb-308d-4b02-a059-394a2697ea8f",
   "metadata": {},
   "source": [
    "<h4>Gestion de la colonne \"Duration\"</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "f6206dce-2c04-48bc-9cf4-05bb4ea27741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type de données initial : <U10\n",
      "Valeurs uniques après correction dans la colonne 'type' : ['Movie' 'TV Show' 'nan']\n",
      "Type de données après correction : <U10\n"
     ]
    }
   ],
   "source": [
    "# Exemple de données pour simuler les colonnes existantes\n",
    "data_cleaned = np.array([\n",
    "    ('Movie', '90 min', None),\n",
    "    ('TV Show', '3 seasons', None),\n",
    "    ('William Wyler', '120 min', None),\n",
    "    ('nan', '150 min', None),\n",
    "    ('type', '90 min', None),\n",
    "], dtype=[('type', 'U10'), ('duration', 'U10'), ('other', 'U10')])\n",
    "\n",
    "# Vérifier le type de données de la colonne 'type'\n",
    "print(\"Type de données initial :\", data_cleaned['type'].dtype)\n",
    "\n",
    "# Remplacer les chaînes 'nan' par np.nan et nettoyer les espaces\n",
    "data_cleaned['type'] = np.where(data_cleaned['type'] == 'nan', np.nan, data_cleaned['type'])\n",
    "\n",
    "# Enlever les espaces\n",
    "data_cleaned['type'] = np.array([t.strip() if isinstance(t, str) else t for t in data_cleaned['type']])\n",
    "\n",
    "# Définir les types valides\n",
    "valid_types = ['Movie', 'TV Show']\n",
    "\n",
    "# Remplacer les valeurs non valides par np.nan\n",
    "data_cleaned['type'] = np.where(np.isin(data_cleaned['type'], valid_types), data_cleaned['type'], np.nan)\n",
    "\n",
    "# Vérifier à nouveau les valeurs uniques\n",
    "unique_types_after_correction = np.unique(data_cleaned['type'])\n",
    "print(\"Valeurs uniques après correction dans la colonne 'type' :\", unique_types_after_correction)\n",
    "\n",
    "# Vérifier le type de données après remplacement\n",
    "print(\"Type de données après correction :\", data_cleaned['type'].dtype)\n",
    "\n",
    "# Réessayer l'assertion\n",
    "assert all(np.isin(data_cleaned['type'], valid_types + [np.nan]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5569956d-6eb9-46bd-964b-1cd97fc54c36",
   "metadata": {},
   "source": [
    "<h4> Création de DataFrames annexes pour les valeurs séparées par des virgules</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "83baddd5-6a91-4b38-ab1d-28a1479d4dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noms des colonnes : ('type', 'duration', 'country', 'listed_in', 'cast')\n",
      "Countries Exploded: ['USA' 'UK' 'France' 'Germany' 'Spain']\n",
      "Categories Exploded: ['Action' ' Drama' 'Comedy' ' Family' 'Thriller' 'Action' 'Drama']\n",
      "Cast Exploded: ['jean' ' paul' 'max' ' joe' 'Nick' ' sophie' 'will' ' mina' 'sophia'\n",
      " ' Alex']\n"
     ]
    }
   ],
   "source": [
    "# Exemple de données pour simuler les colonnes existantes\n",
    "data_cleaned = np.array([\n",
    "    ('Movie', '90 min', 'USA', 'Action, Drama', 'jean, paul'),\n",
    "    ('TV Show', '3 seasons', 'UK', 'Comedy, Family', 'max, joe'),\n",
    "    ('TV Show', '2 seasons', 'France', 'Thriller', 'Nick, sophie'),\n",
    "    ('Movie', '120 min', 'Germany', 'Action', 'will, mina'),\n",
    "    ('TV Show', '1 season', 'Spain', 'Drama', 'sophia, Alex'),\n",
    "], dtype=[('type', 'U10'), ('duration', 'U10'), ('country', 'U20'), ('listed_in', 'U50'), ('cast', 'U50')])\n",
    "\n",
    "# Vérifier les noms des colonnes\n",
    "print(\"Noms des colonnes :\", data_cleaned.dtype.names)\n",
    "\n",
    "# Initialiser des listes pour les nouvelles colonnes\n",
    "countries_list = []\n",
    "categories_list = []\n",
    "cast_list = []\n",
    "\n",
    "# Remplir les nouvelles listes\n",
    "for i in range(data_cleaned.shape[0]):\n",
    "    # Pour la colonne \"country\"\n",
    "    countries = data_cleaned['country'][i].split(',') if isinstance(data_cleaned['country'][i], str) else []\n",
    "    countries_list.extend(countries)\n",
    "\n",
    "    # Pour la colonne \"listed_in\"\n",
    "    categories = data_cleaned['listed_in'][i].split(',') if isinstance(data_cleaned['listed_in'][i], str) else []\n",
    "    categories_list.extend(categories)\n",
    "\n",
    "    # Pour la colonne \"cast\"\n",
    "    cast = data_cleaned['cast'][i].split(',') if isinstance(data_cleaned['cast'][i], str) else []\n",
    "    cast_list.extend(cast)\n",
    "\n",
    "# Convertir les listes en tableaux NumPy\n",
    "countries_exploded = np.array(countries_list, dtype=object)\n",
    "categories_exploded = np.array(categories_list, dtype=object)\n",
    "cast_exploded = np.array(cast_list, dtype=object)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Countries Exploded:\", countries_exploded)\n",
    "print(\"Categories Exploded:\", categories_exploded)\n",
    "print(\"Cast Exploded:\", cast_exploded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64669c-21ce-4cbb-a172-33ca91827dab",
   "metadata": {},
   "source": [
    "<h4> Suppression des colonnes transformées</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "30db22c9-39d6-4232-93eb-49b26c227331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les noms des colonnes à conserver\n",
    "columns_to_keep = [name for name in data_cleaned.dtype.names if name not in ['country', 'listed_in', 'cast']]\n",
    "\n",
    "# Créer un nouveau tableau structuré avec les colonnes à conserver\n",
    "new_data_cleaned = np.zeros(data_cleaned.shape[0], dtype=[(name, data_cleaned.dtype[name]) for name in columns_to_keep])\n",
    "\n",
    "# Remplir le nouveau tableau\n",
    "for name in columns_to_keep:\n",
    "    new_data_cleaned[name] = data_cleaned[name]\n",
    "\n",
    "# Réassigner le nouveau tableau à data_cleaned si nécessaire\n",
    "data_cleaned = new_data_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff860ad-c108-42a8-98ad-43b3ccc8c1f0",
   "metadata": {},
   "source": [
    "<h4>Création de colonnes temporelles</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "bbcacd06-6c3e-4e77-9760-c667732b3959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Movie', '90 min', 'USA', 'Action, Drama', 'jean, paul', '2023', '1', 'Sunday')\n",
      " ('TV Show', '3 seasons', 'UK', 'Comedy, Family', 'max, joe', '2022', '2', 'Tuesday')\n",
      " ('TV Show', '2 seasons', 'France', 'Thriller', 'Nick, sophie', '2021', '3', 'Monday')\n",
      " ('Movie', '120 min', 'Germany', 'Action', 'will, mina', 'None', 'No', 'None')\n",
      " ('TV Show', '1 season', 'Spain', 'Drama', 'sophia, Alex', 'None', 'No', 'None')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Définir les données existantes\n",
    "data_cleaned = np.array([\n",
    "    ('Movie', '90 min', 'USA', 'Action, Drama', 'jean, paul'),\n",
    "    ('TV Show', '3 seasons', 'UK', 'Comedy, Family', 'max, joe'),\n",
    "    ('TV Show', '2 seasons', 'France', 'Thriller', 'Nick, sophie'),\n",
    "    ('Movie', '120 min', 'Germany', 'Action', 'will, mina'),\n",
    "    ('TV Show', '1 season', 'Spain', 'Drama', 'sophia, Alex'),\n",
    "], dtype=[('type', 'U10'), ('duration', 'U10'), ('country', 'U20'), ('listed_in', 'U50'), ('cast', 'U50')])\n",
    "\n",
    "# Exemple de dates ajoutées\n",
    "date_added_as_datetime = [\n",
    "    datetime(2023, 1, 1),\n",
    "    datetime(2022, 2, 1),\n",
    "    datetime(2021, 3, 1),\n",
    "    None,  # Ajout d'une valeur None pour correspondre aux 5 entrées\n",
    "    None   # Ajout d'une autre valeur None\n",
    "]\n",
    "\n",
    "# Initialiser des listes pour les nouvelles colonnes\n",
    "year_added = []\n",
    "month_added = []\n",
    "day_of_week_added = []\n",
    "\n",
    "# Remplir les nouvelles colonnes\n",
    "for date in date_added_as_datetime:\n",
    "    if isinstance(date, datetime):\n",
    "        year_added.append(date.year)\n",
    "        month_added.append(date.month)\n",
    "        day_of_week_added.append(date.strftime('%A'))  # Nom du jour de la semaine\n",
    "    else:\n",
    "        year_added.append(None)\n",
    "        month_added.append(None)\n",
    "        day_of_week_added.append(None)\n",
    "\n",
    "# Convertir les listes en tableaux NumPy\n",
    "year_added = np.array(year_added, dtype=object)\n",
    "month_added = np.array(month_added, dtype=object)\n",
    "day_of_week_added = np.array(day_of_week_added, dtype=object)\n",
    "\n",
    "# Créer un nouveau tableau structuré avec les nouvelles colonnes\n",
    "data_with_new_columns = np.zeros(data_cleaned.shape[0], dtype=[\n",
    "    ('type', 'U10'),\n",
    "    ('duration', 'U10'),\n",
    "    ('country', 'U20'),\n",
    "    ('listed_in', 'U50'),\n",
    "    ('cast', 'U50'),\n",
    "    ('year_added', 'U4'),\n",
    "    ('month_added', 'U2'),\n",
    "    ('day_of_week_added', 'U10')\n",
    "])\n",
    "\n",
    "# Copier les données existantes\n",
    "data_with_new_columns['type'] = data_cleaned['type']\n",
    "data_with_new_columns['duration'] = data_cleaned['duration']\n",
    "data_with_new_columns['country'] = data_cleaned['country']\n",
    "data_with_new_columns['listed_in'] = data_cleaned['listed_in']\n",
    "data_with_new_columns['cast'] = data_cleaned['cast']\n",
    "data_with_new_columns['year_added'] = year_added\n",
    "data_with_new_columns['month_added'] = month_added\n",
    "data_with_new_columns['day_of_week_added'] = day_of_week_added\n",
    "\n",
    "# Afficher le résultat\n",
    "print(data_with_new_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f6272d-9be7-41dc-bea1-331c95da522d",
   "metadata": {},
   "source": [
    "<h4>Affichage des résultats</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "a83400f4-8084-49aa-85cd-d5c2c0a0009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Movie', '90 min', 'USA', 'Action, Drama', 'jean, paul')\n",
      " ('TV Show', '3 seasons', 'UK', 'Comedy, Family', 'max, joe')\n",
      " ('TV Show', '2 seasons', 'France', 'Thriller', 'Nick, sophie')\n",
      " ('Movie', '120 min', 'Germany', 'Action', 'will, mina')\n",
      " ('TV Show', '1 season', 'Spain', 'Drama', 'sophia, Alex')]\n",
      "Countries Exploded:\n",
      "['USA' 'UK' 'France' 'Germany' 'Spain']\n",
      "Categories Exploded:\n",
      "['Action' ' Drama' 'Comedy' ' Family' 'Thriller']\n",
      "Cast List:\n",
      "['jean', ' paul', 'max', ' joe', 'Nick']\n"
     ]
    }
   ],
   "source": [
    "# Afficher les premières lignes de data_cleaned\n",
    "print(data_cleaned[:5])  # Affiche les 5 premières lignes\n",
    "\n",
    "# Afficher les DataFrames annexes\n",
    "print(\"Countries Exploded:\")\n",
    "print(countries_exploded[:5])  # Affiche les 5 premières lignes de countries_exploded\n",
    "\n",
    "print(\"Categories Exploded:\")\n",
    "print(categories_exploded[:5])  # Affiche les 5 premières lignes de categories_exploded\n",
    "\n",
    "print(\"Cast List:\")\n",
    "print(cast_list[:5])  # Affiche les 5 premières lignes de cast_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f702a1",
   "metadata": {},
   "source": [
    "<h1> Analyse des données </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df6a43-e29b-41bd-b44c-c1cfb6747529",
   "metadata": {},
   "source": [
    "<h4>Combien de \"shows\" sont présents dans ce dataset ?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "ff78ebfb-4a0d-482e-ba13-dae349c274d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de shows : 5\n"
     ]
    }
   ],
   "source": [
    "# Nombre total de shows\n",
    "total_shows = data_cleaned.shape[0]\n",
    "print(f\"Total de shows : {total_shows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f596a4-dd5d-4870-9074-77bbb86dea5e",
   "metadata": {},
   "source": [
    "<h4>Quelle est la répartition entre les types 'Movie' et 'TV Show' ?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "5ada5639-161c-425e-aa9a-d717ebb27372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition entre Movies et TV Shows : {'Movie': 2, 'TV Show': 3}\n"
     ]
    }
   ],
   "source": [
    "# 2. Quelle est la répartition entre les types 'Movie' et 'TV Show' ?\n",
    "type_counts = {t: np.sum(data_cleaned['type'] == t) for t in ['Movie', 'TV Show']}\n",
    "print(\"Répartition entre Movies et TV Shows :\", type_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfe1137-5832-497a-aa2f-9ef90b410341",
   "metadata": {},
   "source": [
    "<h4>Quelle est la répartition des ajouts en fonction de l'année ?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "ce8f1ea4-29d6-4273-9565-82fb4554f18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition des ajouts en fonction de l'année :\n",
      "2021: 1\n",
      "2022: 1\n",
      "2023: 1\n",
      "None: 2\n"
     ]
    }
   ],
   "source": [
    "# Répartition des ajouts en fonction de l'année\n",
    "year_counts = {}\n",
    "for year in data_with_new_columns['year_added']:\n",
    "    if year is not None:  # Ignorer les valeurs None\n",
    "        if year in year_counts:\n",
    "            year_counts[year] += 1\n",
    "        else:\n",
    "            year_counts[year] = 1\n",
    "\n",
    "# Affichage de la répartition\n",
    "print(\"Répartition des ajouts en fonction de l'année :\")\n",
    "for year, count in sorted(year_counts.items()):\n",
    "    print(f\"{year}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee1870-349a-4c1b-8087-15e07376f596",
   "metadata": {},
   "source": [
    "<h4> Quel est le top 5 des catégories de shows les plus ajoutées ?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "7eaa4212-1dee-491f-b656-4877ef96672a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 des catégories de shows les plus ajoutées : [('Action', 2), (' Drama', 1), (' Family', 1), ('Comedy', 1), ('Drama', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 4. Quel est le top 5 des catégories de shows les plus ajoutées ?\n",
    "top_categories = {cat: np.sum(categories_exploded == cat) for cat in np.unique(categories_exploded)}\n",
    "top_5_categories = sorted(top_categories.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"Top 5 des catégories de shows les plus ajoutées :\", top_5_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277af5e-5935-418a-993e-c0a62931a742",
   "metadata": {},
   "source": [
    "<h4>Quel est le top 5 des comédiens les plus plébiscités aux États-Unis ?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "842f05e1-6266-47aa-b7ad-1e2df2eb81fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 des comédiens les plus plébiscités : [(' Alex', 1), (' joe', 1), (' mina', 1), (' paul', 1), (' sophie', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 5. Quel est le top 5 des comédiens les plus plébiscités aux États-Unis ?\n",
    "top_actors = {actor: np.sum(cast_exploded == actor) for actor in np.unique(cast_exploded)}\n",
    "top_5_actors = sorted(top_actors.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"Top 5 des comédiens les plus plébiscités :\", top_5_actors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef1817-1f04-47ff-9d8a-2d8fbb80de5c",
   "metadata": {},
   "source": [
    "<h4>Quelle est la répartition des ajouts en fonction du jour de la semaine ?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "2fcb36cd-31c2-466d-b654-0b8e10b44bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition des ajouts par jour de la semaine : {'Monday': 1, 'Sunday': 1, 'Tuesday': 1}\n"
     ]
    }
   ],
   "source": [
    "# Filtrer les valeurs None dans day_of_week_added\n",
    "valid_days = [day for day in day_of_week_added if day is not None]\n",
    "\n",
    "# Répartition des ajouts par jour de la semaine\n",
    "day_counts = {day: valid_days.count(day) for day in np.unique(valid_days)}\n",
    "print(\"Répartition des ajouts par jour de la semaine :\", day_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca48b1ea-97a5-4e99-8eb8-7470d65188ef",
   "metadata": {},
   "source": [
    "<h4>Dans quel pays sont produits le plus de documentaires ?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "762c8c25-6a3f-404d-b8fd-061fd9576052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top pays producteurs de documentaires : []\n"
     ]
    }
   ],
   "source": [
    "# 7. Dans quel pays sont produits le plus de documentaires ?\n",
    "documentaries_index = np.where(data_cleaned['type'] == 'Documentary')[0]\n",
    "documentary_countries = countries_exploded[documentaries_index]\n",
    "top_documentary_countries = {country: np.sum(documentary_countries == country) for country in np.unique(documentary_countries)}\n",
    "top_5_documentary_countries = sorted(top_documentary_countries.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"Top pays producteurs de documentaires :\", top_5_documentary_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4703959c-e223-4afc-a89c-95a40874bb4e",
   "metadata": {},
   "source": [
    "<h4>En moyenne, combien de saisons ont les séries ?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "ad471ab2-0619-404f-9942-3ab4ef0d67a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En moyenne, le nombre de saisons des séries est : 2.0\n"
     ]
    }
   ],
   "source": [
    "# Extraire le nombre de saisons des séries\n",
    "saison_counts = []\n",
    "for duration in data_with_new_columns['duration']:\n",
    "    if 'season' in duration:  # Vérifier si c'est une série\n",
    "        count = int(duration.split()[0])  # Extraire le nombre de saisons\n",
    "        saison_counts.append(count)\n",
    "\n",
    "# Calculer la moyenne\n",
    "if saison_counts:\n",
    "    moyenne_saisons = np.mean(saison_counts)\n",
    "else:\n",
    "    moyenne_saisons = 0\n",
    "\n",
    "print(\"En moyenne, le nombre de saisons des séries est :\", moyenne_saisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696df113-779a-45ac-ad1c-c44bcfa8dd86",
   "metadata": {},
   "source": [
    "<h4>Quelle est la distribution des films en fonction de leur durée (quartiles) ?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "0c1e0d3a-f020-4e43-8810-7845558f8e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quartiles des durées des films : [ 97.5 105.  112.5]\n"
     ]
    }
   ],
   "source": [
    "# 9. Quelle est la distribution des films en fonction de leur durée (quartiles) ?\n",
    "# Remplacez 'duration' par le nom correct de la colonne si nécessaire\n",
    "duration_movies_array = [int(duration.split()[0]) for duration in data_with_new_columns['duration'] if 'min' in duration]\n",
    "\n",
    "# Calculer les quartiles\n",
    "duration_quartiles = np.percentile(duration_movies_array, [25, 50, 75])\n",
    "print(\"Quartiles des durées des films :\", duration_quartiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f27cd2-4ee4-4ae0-889d-4e486b971832",
   "metadata": {},
   "source": [
    "<h4>Combien de shows ont pour thématique la drogue (présence du mot \"drug\" dans la description) ?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "c6d3d633-474d-42fe-8ca9-03abbd5d77eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de shows ayant pour thématique la drogue : 0\n"
     ]
    }
   ],
   "source": [
    "# 10. Combien de shows ont pour thématique la drogue ?\n",
    "# Remplacez 'listed_in' par le nom correct de la colonne contenant les descriptions\n",
    "drug_shows_index = np.where(np.char.find(data_with_new_columns['listed_in'].astype(str), 'drug') != -1)[0]\n",
    "count_drug_shows = drug_shows_index.shape[0]\n",
    "print(f\"Nombre de shows ayant pour thématique la drogue : {count_drug_shows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8601494f-08f7-4890-aa17-5a3973eddbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
